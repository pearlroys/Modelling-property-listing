{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9279d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant packages \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, SGDRegressor, LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import itertools\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c88ed899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import scipy.stats as stats\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ef1631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('listing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd91e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create scrollable table within a small window\n",
    "def create_scrollable_table(df, table_id, title):\n",
    "    html = f'<h3>{title}</h3>'\n",
    "    html += f'<div id=\"{table_id}\" style=\"height:200px; overflow:auto;\">'\n",
    "    html += df.to_html()\n",
    "    html += '</div>'\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41da697c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(988, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098126ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows_with_missing_ratings(df):\n",
    "       \n",
    "       df = df.dropna(subset=['Location_rating'])\n",
    "       return  df\n",
    "\n",
    "df = remove_rows_with_missing_ratings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7c21e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_description_strings(df):\n",
    "\n",
    "        df['Description'].str.replace(\"'About this space',\",\"\")\n",
    "        df['Description'] = df['Description'].str.replace('\"',\"\")\n",
    "        df['Description'] = df['Description'].str.replace(\"' '\",\"\")\n",
    "        df['Description'] = df['Description'].str.replace(\"'\",\"\")\n",
    "        df['Description'] = df['Description'].str.replace(r'\\\\n', '')\n",
    "        df['Description'] = df['Description'].str.replace(r'\\\\n\\\\', '')\n",
    "        df['Description'] = df['Description'].str.split(',', n=1).str[-1]\n",
    "        df['Description'] = df['Description'].str[:-2]\n",
    "        df= df.dropna(subset=['Description'])\n",
    "        return df\n",
    "df = combine_description_strings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cb29852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_default_feature_values(df):\n",
    "\n",
    "        df['beds'] = df['beds'].fillna(1)\n",
    "        df['guests'] = df['guests'].fillna(1)\n",
    "        df['bathrooms'] = df['bathrooms'].fillna(1)\n",
    "        df['bedrooms'] = df['bedrooms'].fillna(1)\n",
    "        return df\n",
    "    \n",
    "def clean_tabular_data(df):\n",
    "    df = set_default_feature_values(df)\n",
    "    df = remove_rows_with_missing_ratings(df)\n",
    "    df = combine_description_strings(df)\n",
    "    try:\n",
    "        df.drop('Unnamed: 19', axis=1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    return df\n",
    "\n",
    "\n",
    "df = set_default_feature_values(df)\n",
    "df = clean_tabular_data(df)\n",
    "# df.to_csv('clean_tabular_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0a10926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>Price_Night</th>\n",
       "      <th>Cleanliness_rating</th>\n",
       "      <th>Accuracy_rating</th>\n",
       "      <th>Communication_rating</th>\n",
       "      <th>Location_rating</th>\n",
       "      <th>Check-in_rating</th>\n",
       "      <th>Value_rating</th>\n",
       "      <th>amenities_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.425301</td>\n",
       "      <td>1.376506</td>\n",
       "      <td>153.934940</td>\n",
       "      <td>5.088916</td>\n",
       "      <td>4.905904</td>\n",
       "      <td>4.933494</td>\n",
       "      <td>4.905060</td>\n",
       "      <td>4.944458</td>\n",
       "      <td>4.769277</td>\n",
       "      <td>35.451446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.844651</td>\n",
       "      <td>0.827813</td>\n",
       "      <td>129.179626</td>\n",
       "      <td>6.776068</td>\n",
       "      <td>0.130051</td>\n",
       "      <td>0.121753</td>\n",
       "      <td>0.120707</td>\n",
       "      <td>0.104018</td>\n",
       "      <td>0.174995</td>\n",
       "      <td>14.256733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1132.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             beds   bathrooms  Price_Night  Cleanliness_rating   \n",
       "count  830.000000  830.000000   830.000000          830.000000  \\\n",
       "mean     2.425301    1.376506   153.934940            5.088916   \n",
       "std      1.844651    0.827813   129.179626            6.776068   \n",
       "min      1.000000    0.000000     3.000000            3.800000   \n",
       "25%      1.000000    1.000000    83.000000            4.800000   \n",
       "50%      2.000000    1.000000   120.000000            4.900000   \n",
       "75%      3.000000    1.500000   176.000000            5.000000   \n",
       "max     17.000000   10.000000  1132.000000          200.000000   \n",
       "\n",
       "       Accuracy_rating  Communication_rating  Location_rating   \n",
       "count       830.000000            830.000000       830.000000  \\\n",
       "mean          4.905904              4.933494         4.905060   \n",
       "std           0.130051              0.121753         0.120707   \n",
       "min           4.000000              3.900000         4.000000   \n",
       "25%           4.900000              4.900000         4.900000   \n",
       "50%           4.900000              5.000000         4.900000   \n",
       "75%           5.000000              5.000000         5.000000   \n",
       "max           5.000000              5.000000         5.000000   \n",
       "\n",
       "       Check-in_rating  Value_rating  amenities_count  \n",
       "count       830.000000    830.000000       830.000000  \n",
       "mean          4.944458      4.769277        35.451446  \n",
       "std           0.104018      0.174995        14.256733  \n",
       "min           3.900000      3.700000         3.000000  \n",
       "25%           4.900000      4.700000        25.000000  \n",
       "50%           5.000000      4.800000        35.000000  \n",
       "75%           5.000000      4.900000        44.000000  \n",
       "max           5.000000      5.000000        84.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features = df.select_dtypes(include=[np.number])\n",
    "numerical_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "438f2503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Summary statistics for numerical data</h3><div id=\"numerical_data\" style=\"height:200px; overflow:auto;\"><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>830.0</td>\n",
       "      <td>2.425301</td>\n",
       "      <td>1.844651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>830.0</td>\n",
       "      <td>1.376506</td>\n",
       "      <td>0.827813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price_Night</th>\n",
       "      <td>830.0</td>\n",
       "      <td>153.934940</td>\n",
       "      <td>129.179626</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>1132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cleanliness_rating</th>\n",
       "      <td>830.0</td>\n",
       "      <td>5.088916</td>\n",
       "      <td>6.776068</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_rating</th>\n",
       "      <td>830.0</td>\n",
       "      <td>4.905904</td>\n",
       "      <td>0.130051</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Communication_rating</th>\n",
       "      <td>830.0</td>\n",
       "      <td>4.933494</td>\n",
       "      <td>0.121753</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location_rating</th>\n",
       "      <td>830.0</td>\n",
       "      <td>4.905060</td>\n",
       "      <td>0.120707</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Check-in_rating</th>\n",
       "      <td>830.0</td>\n",
       "      <td>4.944458</td>\n",
       "      <td>0.104018</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Value_rating</th>\n",
       "      <td>830.0</td>\n",
       "      <td>4.769277</td>\n",
       "      <td>0.174995</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amenities_count</th>\n",
       "      <td>830.0</td>\n",
       "      <td>35.451446</td>\n",
       "      <td>14.256733</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary statistics for numerical dataf\n",
    "numerical_data = df.select_dtypes(include=[np.number])\n",
    "summary_stats = numerical_data.describe().T\n",
    "html_numerical = create_scrollable_table(summary_stats, 'numerical_data', 'Summary statistics for numerical data')\n",
    "\n",
    "display(HTML(html_numerical))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6b270f5",
   "metadata": {},
   "source": [
    "First, we model based on numerical data.\n",
    "We will create a features array that contains all the columns that are numerical.\n",
    "\n",
    "Then we extract the price per night as the label array for predictions/tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03e114ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features (input) and labels (output)\n",
    "features = numerical_data.drop('Price_Night', axis=1)  # Exclude the 'Price_Night' column as the label\n",
    "labels = numerical_data['Price_Night']\n",
    "\n",
    "# Return the features and labels as a tuple\n",
    "features_labels_tuple = (features, labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9cc517e",
   "metadata": {},
   "source": [
    "**Stage 3: Modelling and Prediction**\n",
    "Data is ready for the training of models\n",
    "\n",
    "We will use scikit-learn modules to perform our modelling.\n",
    "\n",
    "The goal is to generate models that will best predict the price per night based on which features the model deems to be of high importance/influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d670e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differentiation of features and labels\n",
    "X = features\n",
    "y = labels\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = list(X.columns))\n",
    "# Splitting into train and test sets\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7385544e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Null values in the dataset</h3><div id=\"null_values\" style=\"height:200px; overflow:auto;\"><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Description</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amenities</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guests</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price_Night</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cleanliness_rating</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_rating</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Communication_rating</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location_rating</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Check-in_rating</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Value_rating</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amenities_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div><h3>Percentage of missing values for each feature</h3><div id=\"missing_percentage\" style=\"height:200px; overflow:auto;\"><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Description</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amenities</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guests</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price_Night</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cleanliness_rating</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_rating</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Communication_rating</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location_rating</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Check-in_rating</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Value_rating</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amenities_count</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "null_values = df.isnull().sum()\n",
    "html_null_values = create_scrollable_table(null_values.to_frame(), 'null_values', 'Null values in the dataset')\n",
    "\n",
    "# Percentage of missing values for each feature\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "html_missing_percentage = create_scrollable_table(missing_percentage.to_frame(), 'missing_percentage', 'Percentage of missing values for each feature')\n",
    "\n",
    "display(HTML(html_null_values + html_missing_percentage))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a53895aa",
   "metadata": {},
   "source": [
    "**Supervised Machine Learning Models**\n",
    "Model 1 - Linear Regression\n",
    "\n",
    "A simple model based on an equation of Regression Problem : Price = a * (Predictor Variables) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8e5dc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept of Regression \t: b  =  153.2855121913216\n"
     ]
    }
   ],
   "source": [
    "# Creating and fitting the model\n",
    "model= LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print('Intercept of Regression \\t: b  = ', model.intercept_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "636ee6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE - Training set: 101.32260787150916\n",
      "RMSE - Test set: 108.15972971500096\n",
      "R^2 - Training set: 0.35761566914283993\n",
      "R^2 - Test set: 0.39235477272030017\n",
      "Mean Squared Error test set: 11698.527132022064\n"
     ]
    }
   ],
   "source": [
    "# Predict Response corresponding to Predictors\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "train_pred = model.predict(X_train)\n",
    "\n",
    "\n",
    "\n",
    "# Compute RMSE for training and test sets\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Compute R^2 for training and test sets\n",
    "r2_train = r2_score(y_train, train_pred)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the performance measures\n",
    "print(\"RMSE - Training set:\", rmse_train)\n",
    "print(\"RMSE - Test set:\", rmse_test)\n",
    "print(\"R^2 - Training set:\", r2_train)\n",
    "print(\"R^2 - Test set:\", r2_test)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error test set:\", mse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a4b64c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SGDRegressor\n",
      "Best Hyperparameters: {'alpha': 0.01, 'max_iter': 1000, 'random_state': 1, 'tol': 0.1}\n",
      "Best MSE: 11473.845737280835\n",
      "\n",
      "Model: LassoRegression\n",
      "Best Hyperparameters: {'alpha': 1, 'max_iter': 1000, 'random_state': 1, 'tol': 0.1}\n",
      "Best MSE: 11651.177778670162\n",
      "\n",
      "Model: RidgeRegression\n",
      "Best Hyperparameters: {'alpha': 1, 'max_iter': 1000, 'random_state': 1, 'tol': 0.1}\n",
      "Best MSE: 11698.145363127878\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SGDRegressor': 11473.845737280835,\n",
       " 'LassoRegression': 11651.177778670162,\n",
       " 'RidgeRegression': 11698.145363127878}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def custom_tune_regression_model_hyperparameters(model_dict, hyperparameters, data):\n",
    "    \"\"\"Performs a grid search over a specified range of hyperparameter values for multiple models.\n",
    "\n",
    "    Args:\n",
    "        model_dict (dict): A dictionary mapping model names to their respective classes\n",
    "        hyperparameters (dict): A dictionary of hyperparameter names mapping to a list of values to be tried\n",
    "        data (list): The training, validation, and test datasets\n",
    "\n",
    "    Returns:\n",
    "        A dictionary mapping model names to their best MSE values\n",
    "    \"\"\"\n",
    "    best_mse_dict = {}\n",
    "\n",
    "    for model_name, model_class in model_dict.items():\n",
    "        best_mse = float('inf')\n",
    "        best_hyperparameters = {}\n",
    "\n",
    "        for param_values in itertools.product(*hyperparameters.values()):\n",
    "            params = dict(zip(hyperparameters.keys(), param_values))\n",
    "\n",
    "            # Create a model instance with the current hyperparameter values\n",
    "            model = model_class(**params)\n",
    "\n",
    "            # Fit the model on the training data\n",
    "            model.fit(data[0], data[2])\n",
    "\n",
    "            # Predict on the validation data\n",
    "            y_pred = model.predict(data[1])\n",
    "\n",
    "            # Calculate the mean squared error\n",
    "            mse = mean_squared_error(data[3], y_pred)\n",
    "\n",
    "            # Check if the current hyperparameters result in a better MSE\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_hyperparameters = params\n",
    "\n",
    "        # Store the best MSE for the current model\n",
    "        best_mse_dict[model_name] = best_mse\n",
    "\n",
    "        # Print the best hyperparameters and MSE for the current model\n",
    "        print(\"Model:\", model_name)\n",
    "        print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "        print(\"Best MSE:\", best_mse)\n",
    "        print()\n",
    "\n",
    "    return best_mse_dict\n",
    "grid_dic =  {'alpha':[0.001,0.01,0.1,1],\n",
    "              'max_iter':[1000,5000,10000,50000],\n",
    "              'random_state': [1],\n",
    "              'tol':[0.1,0.01,0.001,0.001]}\n",
    "data = X_train, X_test, y_train, y_test\n",
    "model_class = { 'SGDRegressor':SGDRegressor,\n",
    "                'LassoRegression': Lasso,\n",
    "                'RidgeRegression': Ridge}\n",
    "\n",
    "\n",
    "custom_tune_regression_model_hyperparameters(model_class, grid_dic, data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eaaacbeb",
   "metadata": {},
   "source": [
    "from our results we can see that SGDRegressor has the lowest MSE and the best hyperparametsers for it are: {'alpha': 0.01, 'max_iter': 1000, 'random_state': 1, 'tol': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3fa9e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ridge',\n",
       " {'alpha': 1, 'max_iter': 1000, 'tol': 0.1},\n",
       " {'mse': 11698.145363127878,\n",
       "  'rmse': 108.15796486217683,\n",
       "  'r2': 0.04572327204431277})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def tune_regression_model_hyperparameters(model, hyperparameters, data):\n",
    "    \"\"\"\n",
    "    This function takes in a regression model class, training, testing and validation datasets, and a dictionary of hyperparameters to tune. It then uses GridSearchCV to find the best hyperparameters for the model, and returns the best model, the best hyperparameters, and performance metrics (validation and test rmse, r2, and mae).\n",
    "\n",
    "    Parameters:\n",
    "        model_dict (dict): A dict of possible models\n",
    "        data: having the four split training and valid data set\n",
    "        hyperparameters (dict): The hyperparameters to be tested by GridSearchCV.\n",
    "\n",
    "    Outputs:\n",
    "        best_model: an instance of the model_class, with the best hyperparameters found\n",
    "        best_hyperparameters: a dictionary of the best hyperparameters found\n",
    "        performance_metrics: a dictionary of performance metrics (validation and test rmse, r2, and mae)\n",
    "    \"\"\"\n",
    "    best_mse = float('inf')\n",
    "    best_model = None\n",
    "    best_hyperparameters = {}\n",
    "    \n",
    "    model = model()\n",
    "    \n",
    "\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(model, hyperparameters, scoring=['neg_mean_squared_error', 'r2'], cv=5, refit='r2')\n",
    "    grid_search.fit(data[0], data[2])\n",
    "\n",
    "    # Get the best model and its hyperparameters\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_hyperparameters = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    # Predict on the validation data\n",
    "    y_pred = best_model.predict(data[1])\n",
    "    \n",
    "    # Calculate the mean squared error\n",
    "    mse = mean_squared_error(data[3], y_pred)\n",
    "    \n",
    "    # Check if the current model and hyperparameters result in a better MSE\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "    # puting the best models and metrics in a dictionary\n",
    "\n",
    "    performance_metrics_dict={}\n",
    "    performance_metrics_dict[\"mse\"] = mse\n",
    "    performance_metrics_dict[\"rmse\"] = mse**(1/2.0)\n",
    "    performance_metrics_dict[\"r2\"] = best_score\n",
    "\n",
    "    return model.__class__.__name__, best_hyperparameters, performance_metrics_dict\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "grid_dic =  {'alpha':[0.001,0.01,0.1,1],\n",
    "              'max_iter':[1000,5000,10000,50000],\n",
    "              'tol':[0.1,0.01,0.001,0.001]}\n",
    "data = X_train, X_test, y_train, y_test\n",
    "model = Ridge\n",
    "model_class = {'LassoRegression': Lasso,\n",
    "                'RidgeRegression': Ridge,\n",
    "                'SGDRegressor':SGDRegressor}\n",
    "tune_regression_model_hyperparameters(model, grid_dic, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbfe2f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is saved\n"
     ]
    }
   ],
   "source": [
    "def save_model(model, hyperparameters, metrics, folder):\n",
    "    \"\"\"This function saves a trained model, its associated hyperparameters and performance metrics to a specified folder.\n",
    "    Parameters:\n",
    "        model: Machine learning model name\n",
    "        hyperparameters: A dictionary of the best hyperparameters used to train the model\n",
    "        metrics: A dictionary of the performance metrics of the model on test and validation sets\n",
    "        model_folder: A string specifying the directory path where the model and associated files will be saved.\"\"\"\n",
    "    \n",
    "    # Create the folder if it doesn't exist\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Save the trained model\n",
    "    model_path = os.path.join(folder, \"model.joblib\")\n",
    "    joblib.dump(model, model_path)\n",
    "\n",
    "    # Save the hyperparameters as a JSON file\n",
    "    hyperparameters_path = os.path.join(folder, \"hyperparameters.json\")\n",
    "    with open(hyperparameters_path, \"w\") as f:\n",
    "        json.dump(hyperparameters, f)\n",
    "\n",
    "    # Save the performance metrics as a JSON file\n",
    "    metrics_path = os.path.join(folder, \"metrics.json\")\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump(metrics, f) \n",
    "        \n",
    "    print ('Model is saved')\n",
    "\n",
    "model = SGDRegressor()\n",
    "hyperparameters = {'alpha': 0.001, 'max_iter': 5000, 'tol': 0.001}\n",
    "metrics = {'mse': 11874.628398645742, 'rmse': 108.97076855123002, 'r2': 0.30426989032666596}\n",
    "save_model(model, hyperparameters, metrics, folder=\"./models/regression/linear_regression/sgd\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82070038",
   "metadata": {},
   "source": [
    "THE SGDREGRESSOR WHICH WAS OUR BEST MODEL WAS SAVED IN THE PREVIOUS CODE USING THE SAVE MDL FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "340fabe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is saved\n"
     ]
    }
   ],
   "source": [
    "def evaluate_all_models(models_dict, hyperparameters, data):\n",
    "    \"\"\"This function Improves the performance of the model by using different models provided by sklearn.\n",
    "such as decision trees, random forests, and gradient boosting  and then saving the best models,\n",
    " hyperparameters and performance metrics to specific folder.\n",
    "    \n",
    "    Outputs:\n",
    "        It saves the best models, hyperparameters and performance metrics of all evaluated models to specific folder.\"\"\"\n",
    "   \n",
    "    best_model_name, best_hyperparameters, performance_metrics_dict = tune_regression_model_hyperparameters(models_dict, hyperparameters, data)\n",
    "    folder_path = f'./models/regression/linear_regression/{best_model_name}'\n",
    "    save_model(best_model_name, best_hyperparameters, performance_metrics_dict, folder_path) \n",
    "\n",
    "# run the code on selected params\n",
    "decision_tree_hyperparameters = {'max_depth': [10, 20, 50], 'min_samples_split': [2, 4, 6, 8], 'min_samples_leaf': [1, 3, 5, 7], 'splitter': ['best', 'random']}\n",
    "random_forest_hyperparameters = {'n_estimators': [50, 100, 150], 'max_depth': [10,20,50], 'min_samples_split': [2, 4, 6, 8], 'min_samples_leaf': [1, 3, 5, 7]}\n",
    "gradient_boost_hyperparameters = {'n_estimators': [50, 100, 150], 'learning_rate': [0.1, 0.001, 0.0001], 'criterion': ['friedman_mse', 'squared_error'], 'min_samples_split': [2, 4, 6, 8], 'min_samples_leaf': [1, 3, 5, 7]}\n",
    "dtr = DecisionTreeRegressor\n",
    "rfr = RandomForestRegressor\n",
    "gbr = GradientBoostingRegressor\n",
    "evaluate_all_models(gbr, gradient_boost_hyperparameters, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c6ab891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd: RMSE: 108.97076855123002\n",
      "DecisionTreeRegressor: RMSE: 118.0366327776913\n",
      "RandomForestRegressor: RMSE: 111.32954559037628\n",
      "GradientBoostingRegressor: RMSE: 116.54049151050316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The model with the lowest RMSE is: sgd'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_best_model(models):\n",
    "    \"\"\"This function compares the Root Mean Squared Error (RMSE) of the trained models on validation set and returns the model with the lowest RMSE.\n",
    "    Parameters:\n",
    "        None\n",
    "    Outputs:\n",
    "        Prints the model name with the lowest RMSE\n",
    "    \"\"\"\n",
    "    best_model = None\n",
    "    best_rmse = float('inf')\n",
    "    best_r2 = 0\n",
    "    for model in models:\n",
    "        with open(f'./models/regression/linear_regression/{model}/metrics.json') as f: \n",
    "            metrics = json.load(f)\n",
    "            validation_r2 = metrics['r2']\n",
    "            validation_rmse = metrics['rmse']\n",
    "            validation_mae = metrics['mse']\n",
    "            print(f'{model}: RMSE: {validation_rmse}')\n",
    "\n",
    "            if validation_rmse < best_rmse:\n",
    "                best_rmse = validation_rmse\n",
    "                best_model = model\n",
    "\n",
    "    \n",
    "    return f'The model with the lowest RMSE is: {best_model}'\n",
    "models = ['sgd', 'DecisionTreeRegressor', 'RandomForestRegressor', 'GradientBoostingRegressor']\n",
    "find_best_model(models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e28ec50",
   "metadata": {},
   "source": [
    "CLASSIFICATION MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83e27ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_load(df, column_list, label):\n",
    "        class_features = df.drop(columns= column_list)\n",
    "        class_labels = df[label]\n",
    "        class_loaded_data = (features,labels)\n",
    "        return class_loaded_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff4bc918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_prepare(df, column_list, label):\n",
    "    \"\"\"Split data into train, test, and validation sets, with normalization. The labels are also encoded.\n",
    "\n",
    "    Parameters:\n",
    "        X (Matrix): Features\n",
    "        y (Vector): Labels\n",
    "  \"\"\"\n",
    "        \n",
    "    # Load the dataset X, y\n",
    "    \n",
    "    X, y = class_load(df, column_list, label)  \n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Preprocess the features (e.g., scaling)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, y_train, X_test_scaled, y_test\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e09bf71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the data we would for classification model\n",
    "   \n",
    "column_list = ['ID', 'Category', 'Title', 'Description', 'Amenities', 'Location', 'url']\n",
    "class_data =split_prepare(df, column_list, 'Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e8ef285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score: 0.006024096385542169\n",
      "Test Precision Score: 0.006024096385542169\n",
      "Test Recall Score: 0.006024096385542169\n",
      "Test F1 Score: 0.006024096385542169\n"
     ]
    }
   ],
   "source": [
    "def log_regression(data):\n",
    "    \n",
    "\n",
    "    # Train a logistic regression model\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(data[0], data[1])\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_test_pred = model.predict(data[2])\n",
    "\n",
    "  # Test set evaluation metrics\n",
    "    print(f'Test Accuracy Score: {accuracy_score(data[3], y_test_pred)}')\n",
    "    print(f'Test Precision Score: {precision_score(data[3], y_test_pred, average=\"micro\")}')\n",
    "    print(f'Test Recall Score: {recall_score(data[3], y_test_pred, average=\"micro\")}')    \n",
    "    print(f'Test F1 Score: {f1_score(data[3], y_test_pred, average=\"micro\")}')\n",
    "\n",
    "log_regression(class_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f86bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_classification_model_hyperparameters(model_class, data, hyperparameters):\n",
    "    \"\"\"\n",
    "    This function performs hyperparameter tuning for a classification model and returns the best model, its hyperparameters, and its performance metrics on a validation set.\n",
    "    \n",
    "    Parameters:\n",
    "    model_class (class), data: X, y values, hyperparameters (dict).\n",
    "    \n",
    "    Returns:\n",
    "    best_model (scikit-learn classifier instance), best_hyperparameters (dict), performance_metrics (dict)\n",
    "    \"\"\"\n",
    "    \n",
    "    performance_metrics = {}\n",
    "    # k_folds = 3\n",
    "    \n",
    "    # used stratified kfold because of the warning of target having classes with only one memeber indicating an imbalaced dataset \n",
    "    # stratified_cv = StratifiedKFold(n_splits=k_folds, shuffle=False, random_state= None)\n",
    "    grid_search = GridSearchCV(model_class, hyperparameters, scoring = 'accuracy', refit= True) \n",
    "    grid_search.fit(data[0], data[1])\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    model_name = model_class.__class__.__name__\n",
    "    best_hyperparameters = grid_search.best_params_\n",
    "\n",
    "    # Provides Validation Metrics\n",
    "    y_test_pred = best_model.predict(data[2])\n",
    "    \n",
    "    \n",
    "    # Accuracy score the same as F1 error in this multiclass classification - precision and recall calculated using weighted average as micro would return the same score as the accuracy\n",
    "    y_test_accuracy = accuracy_score(data[3], y_test_pred)\n",
    "    y_test_precision = precision_score(data[3], y_test_pred, average='weighted')\n",
    "    y_test_recall = recall_score(data[3], y_test_pred, average='macro')\n",
    "\n",
    "    # Maps metrics to the performance metrics dict\n",
    "    performance_metrics['test_accuracy'] = y_test_accuracy\n",
    "    performance_metrics['test_precision'] = y_test_precision\n",
    "    performance_metrics['test_recall'] = y_test_recall\n",
    "\n",
    "    return model_name, best_model, best_hyperparameters, performance_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72a9a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_class_models(models_dict, hyperparameters, data):\n",
    "    model_name, best_model, best_hyperparameters, performance_metrics_dict = tune_classification_model_hyperparameters(models_dict, data, hyperparameters)\n",
    "    folder_path = f'./models/regression/logistic_regression/{model_name}'\n",
    "    save_model(model_name, best_hyperparameters, performance_metrics_dict, folder_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f309c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gbr = GradientBoostingClassifier()\n",
    "# evaluate_class_models(gbr, gradient_boosting_classifier_hyperparameters, class_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc831fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier: accuracy 0.012048192771084338\n",
      "The model with the lowest F1 Score is: GradientBoostingClassifier\n"
     ]
    }
   ],
   "source": [
    "def find_best_class_model(models): \n",
    "    \"\"\"This function compares the F1 error score of the trained models on validation set and returns the model with the lowest F1 score.\n",
    "    Parameters:\n",
    "        None\n",
    "    Outputs:\n",
    "        Prints the model name with the lowest F1 score\n",
    "    \"\"\"  \n",
    "    best_model = None\n",
    "    best_accuracy_score= 0.0\n",
    "    \n",
    "    for model in models:\n",
    "        with open(f'./models/regression/logistic_regression/{model}/metrics.json') as f: \n",
    "            metrics = json.load(f)\n",
    "            validation_accuracy = metrics['test_accuracy']\n",
    "            validation_recall = metrics['test_recall']\n",
    "            validation_precision = metrics['test_precision']\n",
    "            print(f'{model}: accuracy {validation_accuracy}')\n",
    "\n",
    "            if validation_accuracy > best_accuracy_score:\n",
    "                best_accuracy_score = validation_accuracy\n",
    "                best_model = model\n",
    "\n",
    "    return print(f'The model with the lowest F1 Score is: {best_model}')\n",
    "\n",
    "class_models = ['LogisticRegression', 'DecisionTreeClassifier', 'RandomForestClassifier', 'GradientBoostingClassifier']\n",
    "find_best_class_model(class_models)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
